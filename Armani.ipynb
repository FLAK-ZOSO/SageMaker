{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0ac2d6",
   "metadata": {},
   "source": [
    "# Armani SageMaker instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08168326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'csv_serializer' from 'sagemaker.predictor' (/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/predictor.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gmtime, strftime\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csv_serializer\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Define IAM role\u001b[39;00m\n\u001b[1;32m     13\u001b[0m role \u001b[38;5;241m=\u001b[39m get_execution_role()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'csv_serializer' from 'sagemaker.predictor' (/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/predictor.py)"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from time import gmtime, strftime\n",
    "# from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", my_region, \"latest\")\n",
    "\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + xgboost_container + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d07369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'cestino-s3'\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "      s3.create_bucket(Bucket=bucket_name)\n",
    "    else: \n",
    "      s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b703b",
   "metadata": {},
   "source": [
    "The part until now is equal to the [tutorial](https://aws.amazon.com/it/getting-started/hands-on/build-train-deploy-machine-learning-model-sagemaker/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d01984",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  urllib.request.urlretrieve(\"https://leonardo-michelazzo.github.io/LLama-AI/categorizzatore/Armani.csv')\n",
    "except Exception as e:\n",
    "  print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "  model_data = pd.read_csv('./products.csv',index_col=0)\n",
    "  print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7deaf49",
   "metadata": {},
   "source": [
    "Now that we have loaded into model_data the CSV..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_data) # ...and after a bit of debugging...\n",
    "print(type(model_data)) # ...and compensation of the absurd leak of documentation..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9b828",
   "metadata": {},
   "source": [
    "...we start splitting data into the data for training (in this case 70% of the total) an data for testing (the rest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4010ec3f",
   "metadata": {},
   "source": [
    "We should first get what [random_state](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) is.\n",
    "Well, it's just a randomizer I guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986a676a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m      2\u001b[0m     [\n\u001b[1;32m      3\u001b[0m         train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_yes\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m         train_data\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m      5\u001b[0m             [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_no\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_yes\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m         )\n\u001b[1;32m      8\u001b[0m     ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m )\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m boto3\u001b[38;5;241m.\u001b[39mSession()\u001b[38;5;241m.\u001b[39mresource(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mBucket(bucket_name)\u001b[38;5;241m.\u001b[39mObject(\n\u001b[1;32m     15\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     16\u001b[0m         prefix, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m )\u001b[38;5;241m.\u001b[39mupload_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m s3_input_train \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mTrainingInput(\n\u001b[1;32m     20\u001b[0m     s3_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m     content_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        train_data['y_yes'],\n",
    "        train_data.drop(\n",
    "            ['y_no', 'y_yes'],\n",
    "            axis=1\n",
    "        )\n",
    "    ], axis=1\n",
    ").to_csv(\n",
    "    'train.csv',\n",
    "    index=False,\n",
    "    header=False\n",
    ")\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(\n",
    "    os.path.join(\n",
    "        prefix, 'train/train.csv'\n",
    "    )\n",
    ").upload_file('train.csv')\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=f's3://{bucket_name}/{prefix}/train',\n",
    "    content_type='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db39c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
